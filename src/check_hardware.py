"""
Script de Verificaci√≥n de Hardware para V3
Ejecutar este script en el nuevo equipo (Core Ultra) para confirmar acceso a la NPU.
"""
import torch
import whisper
import sys
import platform
import os

def check_system():
    print(f"üñ•Ô∏è  Sistema: {platform.system()} {platform.release()}")
    print(f"üêç Python: {sys.version.split()[0]}")
    
    # 1. Chequeo de Torch (CUDA/CPU)
    print("\n--- 1. PyTorch Backend ---")
    if torch.cuda.is_available():
        print(f"‚úÖ CUDA Disponible: {torch.cuda.get_device_name(0)}")
        print(f"   VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
        device = "cuda"
    else:
        print("‚ö†Ô∏è  CUDA no detectado (Usando CPU)")
        device = "cpu"
        
        # Chequeo espec√≠fico para Intel Extensions for PyTorch (IPEX) - Futuro
        try:
            import intel_extension_for_pytorch as ipex
            print(f"‚úÖ IPEX Detectado (Soporte Intel XPU/NPU)")
        except ImportError:
            print("‚ÑπÔ∏è  IPEX no instalado (Normal si no est√°s en Core Ultra a√∫n)")

    # 2. Chequeo de Whisper
    print("\n--- 2. OpenAI Whisper ---")
    try:
        # Intentar cargar modelo tiny para ver si explota
        print("‚è≥ Probando carga de modelo 'tiny'...")
        model = whisper.load_model("tiny", device=device)
        print(f"‚úÖ Modelo cargado exitosamente en: {model.device}")
    except Exception as e:
        print(f"‚ùå Error cargando Whisper: {e}")

    print("\n---------------------------------------------------")
    if device == "cpu":
        print("üí° TIP: En el Intel Core Ultra, aseg√∫rate de instalar los drivers NPU")
        print("   y considerar usar el backend 'openvino' para m√°xima velocidad.")
    else:
        print(f"üöÄ ¬°Todo listo para volar en {device}!")
        
if __name__ == "__main__":
    check_system()
